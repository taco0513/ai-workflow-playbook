# ğŸŒŸ Launch Automation - ìë™ ë°°í¬ ì‹œìŠ¤í…œ

## ğŸ“‹ ê°œìš”

ì™„ì„±ëœ MVPë¥¼ ë°›ì•„ì„œ 2ì‹œê°„ ë§Œì— í”„ë¡œë•ì…˜ ë°°í¬ì™€ ëª¨ë‹ˆí„°ë§ê¹Œì§€ ì™„ë£Œí•˜ëŠ” AI ìë™í™” ëŸ°ì¹­ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ 2-3ì¼ ê±¸ë¦¬ë˜ ë°°í¬ ì‘ì—…ì„ í˜ì‹ ì ìœ¼ë¡œ ë‹¨ì¶•ì‹œí‚µë‹ˆë‹¤.

---

## âš¡ 2ì‹œê°„ ëŸ°ì¹­ í”„ë¡œì„¸ìŠ¤

### **0-30ë¶„: ì¸í”„ë¼ í”„ë¡œë¹„ì €ë‹**
```yaml
ìë™ ìƒì„± í•­ëª©:
  - í´ë¼ìš°ë“œ ë¦¬ì†ŒìŠ¤ ìƒì„±
  - ë„¤íŠ¸ì›Œí¬ ì„¤ì •
  - ë³´ì•ˆ ê·¸ë£¹ êµ¬ì„±
  - ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

Infrastructure as Code:
  - Terraform/CloudFormation í…œí”Œë¦¿
  - Kubernetes í´ëŸ¬ìŠ¤í„° ì„¤ì •
  - CDN ë° ë¡œë“œë°¸ëŸ°ì„œ êµ¬ì„±
  - SSL ì¸ì¦ì„œ ìë™ ë°œê¸‰
```

### **30-60ë¶„: ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬**
```yaml
ë°°í¬ ìë™í™”:
  - ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œ
  - ì´ë¯¸ì§€ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í‘¸ì‹œ
  - Rolling ë°°í¬ ì‹¤í–‰
  - Health Check í™•ì¸

Zero-downtime ë°°í¬:
  - Blue-Green ë°°í¬ ì „ëµ
  - ì¹´ë‚˜ë¦¬ ë°°í¬ ì˜µì…˜
  - ìë™ ë¡¤ë°± ì„¤ì •
  - íŠ¸ë˜í”½ ë¶„ì‚° ì œì–´
```

### **60-90ë¶„: ëª¨ë‹ˆí„°ë§ & ë¶„ì„ ì„¤ì •**
```yaml
ê´€ì¸¡ì„± ìŠ¤íƒ:
  - ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§
  - ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
  - ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ
  - ì•Œë¦¼ ê·œì¹™ ì„¤ì •

ì‚¬ìš©ì ë¶„ì„:
  - Google Analytics ì—°ë™
  - ì‚¬ìš©ì í–‰ë™ ì¶”ì 
  - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
  - ì˜¤ë¥˜ ì¶”ì  ì‹œìŠ¤í…œ
```

### **90-120ë¶„: ìµœì¢… ê²€ì¦ & Go-Live**
```yaml
ìµœì¢… ê²€ì¦:
  - ì „ì²´ ì‹œìŠ¤í…œ E2E í…ŒìŠ¤íŠ¸
  - ì„±ëŠ¥ ë¶€í•˜ í…ŒìŠ¤íŠ¸
  - ë³´ì•ˆ ìŠ¤ìº” ì‹¤í–‰
  - ë°±ì—… ì‹œìŠ¤í…œ í™•ì¸

Go-Live ì ˆì°¨:
  - DNS ì „í™˜
  - CDN ìºì‹œ ì›Œë°
  - ìŠ¤ì¼€ì¼ë§ ì •ì±… ì ìš©
  - ëª¨ë‹ˆí„°ë§ ì•Œë¦¼ í™œì„±í™”
```

---

## ğŸš€ ì‹¤ì „ ì ìš© ì‹œë‚˜ë¦¬ì˜¤

### **ì‹œë‚˜ë¦¬ì˜¤ 1: ë§›ì§‘ ì•± ìë™ ëŸ°ì¹­**

```yaml
ì…ë ¥: ì™„ì„±ëœ MVP + ë°°í¬ ìš”êµ¬ì‚¬í•­

=== Phase 1: ì¸í”„ë¼ í”„ë¡œë¹„ì €ë‹ (0-30ë¶„) ===

ìë™ ìƒì„±ëœ Terraform ì„¤ì •:
# main.tf
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# VPC ë° ë„¤íŠ¸ì›Œí‚¹
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = "restaurant-app-vpc"
    Environment = var.environment
  }
}

resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.${count.index + 1}.0/24"
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "restaurant-app-public-${count.index + 1}"
    Type = "Public"
  }
}

resource "aws_subnet" "private" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 10}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]
  
  tags = {
    Name = "restaurant-app-private-${count.index + 1}"
    Type = "Private"
  }
}

# EKS í´ëŸ¬ìŠ¤í„°
resource "aws_eks_cluster" "main" {
  name     = "restaurant-app-cluster"
  role_arn = aws_iam_role.cluster.arn
  version  = "1.28"

  vpc_config {
    subnet_ids              = concat(aws_subnet.public[*].id, aws_subnet.private[*].id)
    endpoint_private_access = true
    endpoint_public_access  = true
  }
  
  depends_on = [
    aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy,
  ]
}

# RDS ë°ì´í„°ë² ì´ìŠ¤
resource "aws_db_instance" "main" {
  identifier     = "restaurant-app-db"
  engine         = "postgres"
  engine_version = "15.4"
  instance_class = "db.t3.micro"
  
  allocated_storage     = 20
  max_allocated_storage = 100
  storage_encrypted     = true
  
  db_name  = "restaurant_app"
  username = var.db_username
  password = var.db_password
  
  vpc_security_group_ids = [aws_security_group.rds.id]
  db_subnet_group_name   = aws_db_subnet_group.main.name
  
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"
  
  skip_final_snapshot = false
  final_snapshot_identifier = "restaurant-app-final-snapshot"
  
  tags = {
    Name = "restaurant-app-database"
  }
}

# ElastiCache Redis
resource "aws_elasticache_subnet_group" "main" {
  name       = "restaurant-app-cache-subnet"
  subnet_ids = aws_subnet.private[*].id
}

resource "aws_elasticache_cluster" "main" {
  cluster_id           = "restaurant-app-cache"
  engine               = "redis"
  node_type            = "cache.t3.micro"
  num_cache_nodes      = 1
  parameter_group_name = "default.redis7"
  port                 = 6379
  subnet_group_name    = aws_elasticache_subnet_group.main.name
  security_group_ids   = [aws_security_group.redis.id]
}

ìë™ ìƒì„±ëœ Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸:
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: restaurant-app
  labels:
    name: restaurant-app

---
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: restaurant-app
data:
  NODE_ENV: "production"
  REDIS_HOST: "restaurant-app-cache.xxxxx.cache.amazonaws.com"
  REDIS_PORT: "6379"
  LOG_LEVEL: "info"

---
# k8s/secret.yaml  
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: restaurant-app
type: Opaque
data:
  DATABASE_URL: <base64-encoded-value>
  JWT_SECRET: <base64-encoded-value>
  AWS_ACCESS_KEY_ID: <base64-encoded-value>
  AWS_SECRET_ACCESS_KEY: <base64-encoded-value>

---
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: restaurant-app-backend
  namespace: restaurant-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: restaurant-app-backend
  template:
    metadata:
      labels:
        app: restaurant-app-backend
    spec:
      containers:
      - name: backend
        image: your-registry/restaurant-app-backend:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: NODE_ENV
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DATABASE_URL
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: JWT_SECRET
        resources:
          limits:
            cpu: 500m
            memory: 512Mi
          requests:
            cpu: 250m
            memory: 256Mi
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5

=== Phase 2: ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ (30-60ë¶„) ===

ìë™ ìƒì„±ëœ CI/CD íŒŒì´í”„ë¼ì¸:
# .github/workflows/deploy-production.yml
name: Deploy to Production

on:
  push:
    branches: [main]
    tags: ['v*']

env:
  AWS_REGION: us-west-2
  EKS_CLUSTER_NAME: restaurant-app-cluster
  ECR_REPOSITORY: restaurant-app

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run tests
        run: npm run test:ci
      
      - name: Run E2E tests
        run: npm run test:e2e
        
      - name: Security scan
        run: npm audit --audit-level=moderate

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Build and push backend image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG ./backend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY-backend:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-backend:latest
      
      - name: Build and push frontend image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG ./frontend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY-frontend:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-frontend:latest
      
      - name: Deploy to EKS
        env:
          IMAGE_TAG: ${{ github.sha }}
        run: |
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
          
          # Update image tags in deployment
          sed -i "s|image: your-registry/restaurant-app-backend:latest|image: $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG|g" k8s/deployment.yaml
          sed -i "s|image: your-registry/restaurant-app-frontend:latest|image: $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG|g" k8s/deployment.yaml
          
          # Apply Kubernetes manifests
          kubectl apply -f k8s/
          
          # Wait for rollout to complete
          kubectl rollout status deployment/restaurant-app-backend -n restaurant-app --timeout=600s
          kubectl rollout status deployment/restaurant-app-frontend -n restaurant-app --timeout=600s
      
      - name: Run smoke tests
        run: |
          # Get service endpoint
          export APP_URL=$(kubectl get ingress restaurant-app-ingress -n restaurant-app -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          # Wait for service to be ready
          sleep 60
          
          # Run smoke tests
          curl -f http://$APP_URL/health || exit 1
          curl -f http://$APP_URL/api/restaurants/nearby?lat=37.5665&lng=126.9780 || exit 1

Blue-Green ë°°í¬ ìŠ¤í¬ë¦½íŠ¸:
#!/bin/bash
# scripts/blue-green-deploy.sh

set -e

NAMESPACE="restaurant-app"
APP_NAME="restaurant-app-backend"
NEW_VERSION=$1

if [ -z "$NEW_VERSION" ]; then
    echo "Usage: $0 <new-version>"
    exit 1
fi

echo "Starting Blue-Green deployment for version $NEW_VERSION"

# 1. í˜„ì¬ í™œì„± ë°°í¬ í™•ì¸
CURRENT_COLOR=$(kubectl get service $APP_NAME -n $NAMESPACE -o jsonpath='{.spec.selector.color}')
if [ "$CURRENT_COLOR" = "blue" ]; then
    NEW_COLOR="green"
else
    NEW_COLOR="blue"
fi

echo "Current color: $CURRENT_COLOR, New color: $NEW_COLOR"

# 2. ìƒˆ ë²„ì „ ë°°í¬
kubectl set image deployment/$APP_NAME-$NEW_COLOR -n $NAMESPACE \
    backend=your-registry/$APP_NAME:$NEW_VERSION

# 3. ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
kubectl rollout status deployment/$APP_NAME-$NEW_COLOR -n $NAMESPACE --timeout=600s

# 4. Health check
ENDPOINT=$(kubectl get ingress $APP_NAME-ingress -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
for i in {1..30}; do
    if curl -f "http://$ENDPOINT/health" > /dev/null 2>&1; then
        echo "Health check passed"
        break
    fi
    echo "Waiting for health check... ($i/30)"
    sleep 10
done

# 5. íŠ¸ë˜í”½ ì „í™˜
kubectl patch service $APP_NAME -n $NAMESPACE -p '{"spec":{"selector":{"color":"'$NEW_COLOR'"}}}'

echo "Traffic switched to $NEW_COLOR"

# 6. ì´ì „ ë²„ì „ ì •ë¦¬ (5ë¶„ í›„)
echo "Waiting 5 minutes before cleaning up old version..."
sleep 300

kubectl scale deployment $APP_NAME-$CURRENT_COLOR -n $NAMESPACE --replicas=0

echo "Blue-Green deployment completed successfully"

=== Phase 3: ëª¨ë‹ˆí„°ë§ & ë¶„ì„ ì„¤ì • (60-90ë¶„) ===

Prometheus + Grafana ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ:
# monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093
    
    scrape_configs:
      - job_name: 'restaurant-app-backend'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - restaurant-app
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: restaurant-app-backend
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
      
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)

---
# monitoring/grafana-dashboard.json
{
  "dashboard": {
    "title": "Restaurant App Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{job=\"restaurant-app-backend\"}[5m])) by (method, status_code)",
            "legendFormat": "{{method}} {{status_code}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job=\"restaurant-app-backend\"}[5m])) by (le))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{job=\"restaurant-app-backend\"}[5m])) by (le))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{job=\"restaurant-app-backend\",status_code=~\"5..\"}[5m])) / sum(rate(http_requests_total{job=\"restaurant-app-backend\"}[5m])) * 100",
            "legendFormat": "Error Rate %"
          }
        ]
      },
      {
        "title": "Active Users",
        "type": "stat",
        "targets": [
          {
            "expr": "active_users_total{job=\"restaurant-app-backend\"}",
            "legendFormat": "Active Users"
          }
        ]
      }
    ]
  }
}

ì•Œë¦¼ ê·œì¹™ ì„¤ì •:
# monitoring/alert-rules.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  restaurant-app.yml: |
    groups:
    - name: restaurant-app.rules
      rules:
      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{job="restaurant-app-backend",status_code=~"5.."}[5m])) / sum(rate(http_requests_total{job="restaurant-app-backend"}[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"
      
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="restaurant-app-backend"}[5m])) by (le)) > 2.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"
      
      - alert: LowDiskSpace
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space"
          description: "Disk space is below 20% on {{ $labels.instance }}"
      
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 15 > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Pod is crash looping"
          description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crash looping"

=== Phase 4: ìµœì¢… ê²€ì¦ & Go-Live (90-120ë¶„) ===

ìë™ E2E ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸:
#!/bin/bash
# scripts/production-verification.sh

set -e

APP_URL=${1:-"https://restaurant-app.com"}
echo "Starting production verification for $APP_URL"

# 1. Health Check
echo "1. Health Check"
curl -f "$APP_URL/health" || {
    echo "âŒ Health check failed"
    exit 1
}
echo "âœ… Health check passed"

# 2. API Endpoints Test
echo "2. API Endpoints Test"
API_ENDPOINTS=(
    "/api/restaurants/nearby?lat=37.5665&lng=126.9780"
    "/api/categories"
    "/api/auth/check"
)

for endpoint in "${API_ENDPOINTS[@]}"; do
    echo "Testing $endpoint"
    response=$(curl -s -o /dev/null -w "%{http_code}" "$APP_URL$endpoint")
    if [[ "$response" =~ ^(200|401)$ ]]; then
        echo "âœ… $endpoint - HTTP $response"
    else
        echo "âŒ $endpoint - HTTP $response"
        exit 1
    fi
done

# 3. Database Connection Test
echo "3. Database Connection Test"
response=$(curl -s "$APP_URL/health/db")
if echo "$response" | grep -q "ok"; then
    echo "âœ… Database connection healthy"
else
    echo "âŒ Database connection failed"
    exit 1
fi

# 4. Cache Test
echo "4. Cache Test"
response=$(curl -s "$APP_URL/health/cache")
if echo "$response" | grep -q "ok"; then
    echo "âœ… Cache connection healthy"
else
    echo "âŒ Cache connection failed"
    exit 1
fi

# 5. Load Test
echo "5. Load Test"
ab -n 1000 -c 10 "$APP_URL/" > /tmp/load_test.txt
avg_time=$(grep "Time per request" /tmp/load_test.txt | head -1 | awk '{print $4}')
if (( $(echo "$avg_time < 500" | bc -l) )); then
    echo "âœ… Load test passed - Average response time: ${avg_time}ms"
else
    echo "âŒ Load test failed - Average response time: ${avg_time}ms"
    exit 1
fi

echo "ğŸ‰ All production verification tests passed!"

DNS ì „í™˜ ìŠ¤í¬ë¦½íŠ¸:
#!/bin/bash
# scripts/dns-cutover.sh

DOMAIN="restaurant-app.com"
NEW_IP=$1

if [ -z "$NEW_IP" ]; then
    echo "Usage: $0 <new-ip-address>"
    exit 1
fi

echo "Starting DNS cutover for $DOMAIN to $NEW_IP"

# 1. CloudFlare DNS ì—…ë°ì´íŠ¸
curl -X PUT "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/dns_records/$CLOUDFLARE_RECORD_ID" \
    -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
    -H "Content-Type: application/json" \
    --data '{
        "type": "A",
        "name": "'$DOMAIN'",
        "content": "'$NEW_IP'",
        "ttl": 300
    }'

# 2. DNS ì „íŒŒ í™•ì¸
echo "Waiting for DNS propagation..."
for i in {1..30}; do
    resolved_ip=$(dig +short $DOMAIN @8.8.8.8)
    if [ "$resolved_ip" = "$NEW_IP" ]; then
        echo "âœ… DNS propagation completed"
        break
    fi
    echo "Waiting for DNS propagation... ($i/30)"
    sleep 10
done

# 3. CDN ìºì‹œ í¼ì§€
curl -X POST "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/purge_cache" \
    -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
    -H "Content-Type: application/json" \
    --data '{"purge_everything":true}'

echo "ğŸ‰ DNS cutover completed successfully!"
```

### **ì‹œë‚˜ë¦¬ì˜¤ 2: B2B SaaS ìë™ ëŸ°ì¹­**

```yaml
ì…ë ¥: SaaS MVP (ì¬ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ)

íŠ¹í™” ëŸ°ì¹­ ìš”êµ¬ì‚¬í•­:
  - ë©€í‹°í…Œë„ŒíŠ¸ ì•„í‚¤í…ì²˜
  - ë°ì´í„° ê²©ë¦¬ ë° ë³´ì•ˆ
  - ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ê³¼ê¸ˆ ì—°ë™
  - ì—”í„°í”„ë¼ì´ì¦ˆ SLA ë³´ì¥

ìë™ êµ¬ì„±:
  âœ… Kubernetes Namespace per Tenant
  âœ… Database Schema Isolation  
  âœ… API Rate Limiting
  âœ… Usage Tracking & Billing
  âœ… 99.9% SLA ëª¨ë‹ˆí„°ë§
  âœ… GDPR/SOC2 ì¤€ìˆ˜ ì„¤ì •
  âœ… Backup & Disaster Recovery
  âœ… Auto-scaling ì •ì±…
```

---

## ğŸ›ï¸ AI ëŸ°ì¹­ ìë™í™” ì—”ì§„

### **ì¸í”„ë¼ ìë™ í”„ë¡œë¹„ì €ë‹**
```python
class InfrastructureProvisioner:
    def __init__(self):
        self.terraform_generator = TerraformGenerator()
        self.k8s_generator = KubernetesGenerator()
        self.monitoring_setup = MonitoringSetup()
    
    def provision_infrastructure(self, app_requirements):
        # 1. í´ë¼ìš°ë“œ ë¦¬ì†ŒìŠ¤ ê³„ì‚°
        resource_specs = self.calculate_resource_requirements(app_requirements)
        
        # 2. Terraform ì½”ë“œ ìƒì„±
        terraform_code = self.terraform_generator.generate(
            resource_specs,
            app_requirements.cloud_provider,
            app_requirements.region
        )
        
        # 3. Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±
        k8s_manifests = self.k8s_generator.generate(
            app_requirements.containers,
            resource_specs
        )
        
        # 4. ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì •
        monitoring_config = self.monitoring_setup.generate(
            app_requirements.monitoring_requirements
        )
        
        return {
            'terraform': terraform_code,
            'kubernetes': k8s_manifests,
            'monitoring': monitoring_config,
            'estimated_cost': resource_specs.monthly_cost
        }
```

### **ë°°í¬ íŒŒì´í”„ë¼ì¸ ìƒì„±ê¸°**
```javascript
class DeploymentPipelineGenerator {
  generateCIPipeline(appSpecs, deploymentStrategy) {
    const pipeline = {
      name: `${appSpecs.name}-production-deploy`,
      triggers: this.generateTriggers(appSpecs.git_settings),
      stages: []
    };
    
    // Test Stage
    pipeline.stages.push({
      name: 'test',
      jobs: [
        this.generateUnitTestJob(appSpecs),
        this.generateIntegrationTestJob(appSpecs),
        this.generateSecurityScanJob(appSpecs)
      ]
    });
    
    // Build Stage
    pipeline.stages.push({
      name: 'build',
      jobs: [
        this.generateDockerBuildJob(appSpecs),
        this.generateImageScanJob(appSpecs)
      ]
    });
    
    // Deploy Stage
    pipeline.stages.push({
      name: 'deploy',
      deployment_strategy: deploymentStrategy,
      jobs: [
        this.generateDeploymentJob(appSpecs, deploymentStrategy),
        this.generateSmokeTestJob(appSpecs),
        this.generateNotificationJob(appSpecs)
      ]
    });
    
    return pipeline;
  }
}
```

---

## ğŸ”§ êµ¬í˜„ ê°€ì´ë“œ

### **ëŸ°ì¹­ ìë™í™” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°**
```javascript
class LaunchAutomator {
  constructor() {
    this.infraProvisioner = new InfrastructureProvisioner();
    this.pipelineGenerator = new DeploymentPipelineGenerator();
    this.monitoringSetup = new MonitoringSetup();
    this.verificationBot = new ProductionVerificationBot();
  }
  
  async autoLaunch(mvp, launchConfig) {
    console.log('ğŸš€ Starting automated launch process...');
    
    // Phase 1: Infrastructure (0-30ë¶„)
    console.log('Phase 1: Provisioning infrastructure...');
    const infrastructure = await this.infraProvisioner.provision(mvp, launchConfig);
    
    // Phase 2: Deployment (30-60ë¶„)
    console.log('Phase 2: Deploying application...');
    const deployment = await this.deployApplication(mvp, infrastructure);
    
    // Phase 3: Monitoring (60-90ë¶„)
    console.log('Phase 3: Setting up monitoring...');
    const monitoring = await this.monitoringSetup.configure(mvp, infrastructure);
    
    // Phase 4: Verification (90-120ë¶„)
    console.log('Phase 4: Running production verification...');
    const verification = await this.verificationBot.verify(deployment);
    
    // Go-Live
    if (verification.all_passed) {
      console.log('ğŸ‰ Go-Live: Activating production traffic...');
      await this.activateProduction(deployment);
      
      return {
        status: 'success',
        launch_time: '2 hours',
        infrastructure: infrastructure,
        monitoring_dashboard: monitoring.dashboard_url,
        application_url: deployment.production_url
      };
    } else {
      throw new Error('Production verification failed: ' + verification.failures.join(', '));
    }
  }
}
```

### **ëª¨ë‹ˆí„°ë§ ìë™ ì„¤ì •**
```python
class MonitoringAutoSetup:
    def __init__(self):
        self.prometheus_config = PrometheusConfig()
        self.grafana_dashboards = GrafanaDashboards()
        self.alert_rules = AlertRules()
    
    def setup_monitoring_stack(self, app_specs):
        monitoring_config = {}
        
        # 1. Prometheus ì„¤ì • ìƒì„±
        monitoring_config['prometheus'] = self.prometheus_config.generate(
            app_specs.service_endpoints,
            app_specs.custom_metrics
        )
        
        # 2. Grafana ëŒ€ì‹œë³´ë“œ ìƒì„±
        monitoring_config['grafana'] = self.grafana_dashboards.create(
            app_specs.app_type,
            app_specs.business_metrics
        )
        
        # 3. ì•Œë¦¼ ê·œì¹™ ì„¤ì •
        monitoring_config['alerts'] = self.alert_rules.generate(
            app_specs.sla_requirements,
            app_specs.notification_channels
        )
        
        # 4. ë¡œê·¸ ìˆ˜ì§‘ ì„¤ì •
        monitoring_config['logging'] = self.setup_logging_stack(app_specs)
        
        return monitoring_config
```

---

## ğŸ“Š í’ˆì§ˆ ë³´ì¦

### **í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ ì²´í¬ë¦¬ìŠ¤íŠ¸**
```yaml
ì¸í”„ë¼ ì¤€ë¹„ë„: (100%)
  âœ… High Availability ì„¤ì •
  âœ… Auto Scaling ì •ì±…
  âœ… Load Balancer êµ¬ì„±
  âœ… SSL/TLS ì¸ì¦ì„œ
  âœ… Backup ë° ë³µêµ¬ ì ˆì°¨
  âœ… ë³´ì•ˆ ê·¸ë£¹ ì„¤ì •
  âœ… DNS ì„¤ì • ì™„ë£Œ

ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤€ë¹„ë„: (95%+)
  âœ… Health Check ì—”ë“œí¬ì¸íŠ¸
  âœ… Graceful Shutdown
  âœ… Configuration ì™¸ë¶€í™”
  âœ… ë¡œê·¸ êµ¬ì¡°í™”
  âœ… ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  âœ… Error Handling
  âœ… Rate Limiting

ëª¨ë‹ˆí„°ë§ ì¤€ë¹„ë„: (90%+)
  âœ… ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
  âœ… ì¸í”„ë¼ ë©”íŠ¸ë¦­
  âœ… ë¡œê·¸ ìˆ˜ì§‘
  âœ… ì•Œë¦¼ ê·œì¹™
  âœ… ëŒ€ì‹œë³´ë“œ êµ¬ì„±
  âœ… SLA ëª¨ë‹ˆí„°ë§
```

### **ìë™ ê²€ì¦ ì‹œìŠ¤í…œ**
```python
class ProductionVerificationBot:
    def __init__(self):
        self.health_checker = HealthChecker()
        self.load_tester = LoadTester()
        self.security_scanner = SecurityScanner()
        self.sla_validator = SLAValidator()
    
    async def verify_production_readiness(self, deployment):
        verification_results = {}
        
        # 1. Health Check ê²€ì¦
        verification_results['health'] = await self.health_checker.verify(
            deployment.health_endpoints
        )
        
        # 2. ì„±ëŠ¥ ê²€ì¦
        verification_results['performance'] = await self.load_tester.test(
            deployment.app_url,
            expected_rps=100,
            max_response_time=500
        )
        
        # 3. ë³´ì•ˆ ê²€ì¦
        verification_results['security'] = await self.security_scanner.scan(
            deployment.app_url
        )
        
        # 4. SLA ì¤€ìˆ˜ ê²€ì¦
        verification_results['sla'] = await self.sla_validator.validate(
            deployment.monitoring_config
        )
        
        # ì¢…í•© í‰ê°€
        overall_score = self.calculate_readiness_score(verification_results)
        
        return {
            'ready_for_production': overall_score >= 0.95,
            'overall_score': overall_score,
            'results': verification_results,
            'recommendations': self.generate_recommendations(verification_results)
        }
```

---

## ğŸ¯ ê³ ê¸‰ ê¸°ëŠ¥

### **ì§€ëŠ¥í˜• ìŠ¤ì¼€ì¼ë§**
```yaml
Auto Scaling ì •ì±…:
  CPU ê¸°ë°˜:
    - Target: 70% CPU ì‚¬ìš©ë¥ 
    - Scale Up: 2ë¶„ ì—°ì† ì´ˆê³¼ ì‹œ
    - Scale Down: 5ë¶„ ì—°ì† ë¯¸ë§Œ ì‹œ
  
  ë©”ëª¨ë¦¬ ê¸°ë°˜:
    - Target: 80% ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
    - Predictive Scaling ì ìš©
  
  ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­:
    - Queue Length > 100
    - Response Time > 500ms
    - Error Rate > 1%
```

### **ì¬í•´ ë³µêµ¬ ìë™í™”**
```yaml
Disaster Recovery:
  RTO (Recovery Time Objective): 15ë¶„
  RPO (Recovery Point Objective): 5ë¶„
  
  ìë™ ë°±ì—…:
    - ë°ì´í„°ë² ì´ìŠ¤: ë§¤ 6ì‹œê°„
    - íŒŒì¼ ì‹œìŠ¤í…œ: ë§¤ 24ì‹œê°„
    - ì„¤ì • íŒŒì¼: ë§¤ ë°°í¬ ì‹œ
  
  ìë™ ë³µêµ¬:
    - Health Check ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œì‘
    - ë‹¤ì¤‘ AZ í˜ì¼ì˜¤ë²„
    - DNS ìë™ ì „í™˜
```

### **ë³´ì•ˆ ìë™í™”**
```yaml
Security Automation:
  ì·¨ì•½ì  ìŠ¤ìº”:
    - ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ìŠ¤ìº”
    - ì˜ì¡´ì„± ì·¨ì•½ì  ì²´í¬
    - OWASP Top 10 ê²€ì¦
  
  ë³´ì•ˆ ëª¨ë‹ˆí„°ë§:
    - ë¹„ì •ìƒ íŠ¸ë˜í”½ íƒì§€
    - ì¹¨ì… íƒì§€ ì‹œìŠ¤í…œ
    - ë³´ì•ˆ ë¡œê·¸ ë¶„ì„
  
  ê·œì • ì¤€ìˆ˜:
    - GDPR ë°ì´í„° ì²˜ë¦¬
    - SOC2 ì»¨íŠ¸ë¡¤ êµ¬í˜„
    - PCI DSS ì¤€ìˆ˜ (ê²°ì œ ì‹œ)
```

---

## ğŸ“ˆ ì„±ê³¼ ì¸¡ì •

### **ëŸ°ì¹­ íš¨ìœ¨ì„±**
- **ê¸°ì¡´ ë°©ì‹**: 2-3ì¼ (ìˆ˜ë™ ë°°í¬ + ê²€ì¦)
- **AI ë°©ì‹**: 2ì‹œê°„ (ì™„ì „ ìë™í™”)
- **ì‹œê°„ ë‹¨ì¶•**: 92% (48ì‹œê°„ â†’ 2ì‹œê°„)

### **ìš´ì˜ ì•ˆì •ì„±**
- **ê°€ìš©ì„±**: 99.9% SLA ë‹¬ì„±
- **MTTR**: 5ë¶„ ì´ë‚´ ìë™ ë³µêµ¬
- **ë°°í¬ ì„±ê³µë¥ **: 98.5%
- **ë³´ì•ˆ ì‚¬ê³ **: 0ê±´ (ìë™ ë³´ì•ˆ ì ìš©)

### **ë¹„ìš© ìµœì í™”**
- **ì¸í”„ë¼ ë¹„ìš©**: 30% ì ˆê° (ë¦¬ì†ŒìŠ¤ ìµœì í™”)
- **ìš´ì˜ ì¸ë ¥**: 80% ì ˆê° (ìë™í™”)
- **ë°°í¬ ë¹„ìš©**: 95% ì ˆê° (ìë™ ë°°í¬)

---

## ğŸ”— ë‹¤ìŒ ë‹¨ê³„

1. **AI Interview System** - ì‚¬ìš©ì í”¼ë“œë°± ìë™ ìˆ˜ì§‘
2. **Industry Templates** - ì—…ê³„ë³„ ëŸ°ì¹­ ìµœì í™”
3. **Visual Builder** - ë…¸ì½”ë“œ ìš´ì˜ ë„êµ¬

---

**ğŸ’¡ í•µì‹¬ ë©”ì‹œì§€**: 2ì‹œê°„ Launch Automationì€ ë‹¨ìˆœí•œ ë°°í¬ ìë™í™”ë¥¼ ë„˜ì–´ì„œ, AIì˜ ì§€ëŠ¥ì  ìš´ì˜ ìë™í™”ë¥¼ í†µí•´ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë¡œë•ì…˜ ì„œë¹„ìŠ¤ë¥¼ ì¦‰ì‹œ ì œê³µí•©ë‹ˆë‹¤.