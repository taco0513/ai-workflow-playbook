# üåü Launch Automation - ÏûêÎèô Î∞∞Ìè¨ ÏãúÏä§ÌÖú

## üìã Í∞úÏöî

ÏôÑÏÑ±Îêú MVPÎ•º Î∞õÏïÑÏÑú 2ÏãúÍ∞Ñ ÎßåÏóê ÌîÑÎ°úÎçïÏÖò Î∞∞Ìè¨ÏôÄ Î™®ÎãàÌÑ∞ÎßÅÍπåÏßÄ ÏôÑÎ£åÌïòÎäî AI ÏûêÎèôÌôî Îü∞Ïπ≠ ÏãúÏä§ÌÖúÏûÖÎãàÎã§. Ï†ÑÌÜµÏ†ÅÏúºÎ°ú 2-3Ïùº Í±∏Î¶¨Îçò Î∞∞Ìè¨ ÏûëÏóÖÏùÑ ÌòÅÏã†Ï†ÅÏúºÎ°ú Îã®Ï∂ïÏãúÌÇµÎãàÎã§.

---

## ‚ö° 2ÏãúÍ∞Ñ Îü∞Ïπ≠ ÌîÑÎ°úÏÑ∏Ïä§

### **0-30Î∂Ñ: Ïù∏ÌîÑÎùº ÌîÑÎ°úÎπÑÏ†ÄÎãù**
```yaml
ÏûêÎèô ÏÉùÏÑ± Ìï≠Î™©:
  - ÌÅ¥ÎùºÏö∞Îìú Î¶¨ÏÜåÏä§ ÏÉùÏÑ±
  - ÎÑ§Ìä∏ÏõåÌÅ¨ ÏÑ§Ï†ï
  - Î≥¥Ïïà Í∑∏Î£π Íµ¨ÏÑ±
  - Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑ§Ï†ï

Infrastructure as Code:
  - Terraform/CloudFormation ÌÖúÌîåÎ¶ø
  - Kubernetes ÌÅ¥Îü¨Ïä§ÌÑ∞ ÏÑ§Ï†ï
  - CDN Î∞è Î°úÎìúÎ∞∏Îü∞ÏÑú Íµ¨ÏÑ±
  - SSL Ïù∏Ï¶ùÏÑú ÏûêÎèô Î∞úÍ∏â
```

### **30-60Î∂Ñ: Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î∞∞Ìè¨**
```yaml
Î∞∞Ìè¨ ÏûêÎèôÌôî:
  - Ïª®ÌÖåÏù¥ÎÑà Ïù¥ÎØ∏ÏßÄ ÎπåÎìú
  - Ïù¥ÎØ∏ÏßÄ Î†àÏßÄÏä§Ìä∏Î¶¨ Ìë∏Ïãú
  - Rolling Î∞∞Ìè¨ Ïã§Ìñâ
  - Health Check ÌôïÏù∏

Zero-downtime Î∞∞Ìè¨:
  - Blue-Green Î∞∞Ìè¨ Ï†ÑÎûµ
  - Ïπ¥ÎÇòÎ¶¨ Î∞∞Ìè¨ ÏòµÏÖò
  - ÏûêÎèô Î°§Î∞± ÏÑ§Ï†ï
  - Ìä∏ÎûòÌîΩ Î∂ÑÏÇ∞ Ï†úÏñ¥
```

### **60-90Î∂Ñ: Î™®ÎãàÌÑ∞ÎßÅ & Î∂ÑÏÑù ÏÑ§Ï†ï**
```yaml
Í¥ÄÏ∏°ÏÑ± Ïä§ÌÉù:
  - Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î™®ÎãàÌÑ∞ÎßÅ
  - Î°úÍ∑∏ ÏàòÏßë ÏãúÏä§ÌÖú
  - Î©îÌä∏Î¶≠ ÎåÄÏãúÎ≥¥Îìú
  - ÏïåÎ¶º Í∑úÏπô ÏÑ§Ï†ï

ÏÇ¨Ïö©Ïûê Î∂ÑÏÑù:
  - Google Analytics Ïó∞Îèô
  - ÏÇ¨Ïö©Ïûê ÌñâÎèô Ï∂îÏ†Å
  - ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
  - Ïò§Î•ò Ï∂îÏ†Å ÏãúÏä§ÌÖú
```

### **90-120Î∂Ñ: ÏµúÏ¢Ö Í≤ÄÏ¶ù & Go-Live**
```yaml
ÏµúÏ¢Ö Í≤ÄÏ¶ù:
  - Ï†ÑÏ≤¥ ÏãúÏä§ÌÖú E2E ÌÖåÏä§Ìä∏
  - ÏÑ±Îä• Î∂ÄÌïò ÌÖåÏä§Ìä∏
  - Î≥¥Ïïà Ïä§Ï∫î Ïã§Ìñâ
  - Î∞±ÏóÖ ÏãúÏä§ÌÖú ÌôïÏù∏

Go-Live Ï†àÏ∞®:
  - DNS Ï†ÑÌôò
  - CDN Ï∫êÏãú ÏõåÎ∞ç
  - Ïä§ÏºÄÏùºÎßÅ Ï†ïÏ±Ö Ï†ÅÏö©
  - Î™®ÎãàÌÑ∞ÎßÅ ÏïåÎ¶º ÌôúÏÑ±Ìôî
```

---

## üöÄ Ïã§Ï†Ñ Ï†ÅÏö© ÏãúÎÇòÎ¶¨Ïò§

### **ÏãúÎÇòÎ¶¨Ïò§ 1: ÎßõÏßë Ïï± ÏûêÎèô Îü∞Ïπ≠**

```yaml
ÏûÖÎ†•: ÏôÑÏÑ±Îêú MVP + Î∞∞Ìè¨ ÏöîÍµ¨ÏÇ¨Ìï≠

=== Phase 1: Ïù∏ÌîÑÎùº ÌîÑÎ°úÎπÑÏ†ÄÎãù (0-30Î∂Ñ) ===

ÏûêÎèô ÏÉùÏÑ±Îêú Terraform ÏÑ§Ï†ï:
# main.tf
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# VPC Î∞è ÎÑ§Ìä∏ÏõåÌÇπ
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = "restaurant-app-vpc"
    Environment = var.environment
  }
}

resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.${count.index + 1}.0/24"
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "restaurant-app-public-${count.index + 1}"
    Type = "Public"
  }
}

resource "aws_subnet" "private" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 10}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]
  
  tags = {
    Name = "restaurant-app-private-${count.index + 1}"
    Type = "Private"
  }
}

# EKS ÌÅ¥Îü¨Ïä§ÌÑ∞
resource "aws_eks_cluster" "main" {
  name     = "restaurant-app-cluster"
  role_arn = aws_iam_role.cluster.arn
  version  = "1.28"

  vpc_config {
    subnet_ids              = concat(aws_subnet.public[*].id, aws_subnet.private[*].id)
    endpoint_private_access = true
    endpoint_public_access  = true
  }
  
  depends_on = [
    aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy,
  ]
}

# RDS Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§
resource "aws_db_instance" "main" {
  identifier     = "restaurant-app-db"
  engine         = "postgres"
  engine_version = "15.4"
  instance_class = "db.t3.micro"
  
  allocated_storage     = 20
  max_allocated_storage = 100
  storage_encrypted     = true
  
  db_name  = "restaurant_app"
  username = var.db_username
  password = var.db_password
  
  vpc_security_group_ids = [aws_security_group.rds.id]
  db_subnet_group_name   = aws_db_subnet_group.main.name
  
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"
  
  skip_final_snapshot = false
  final_snapshot_identifier = "restaurant-app-final-snapshot"
  
  tags = {
    Name = "restaurant-app-database"
  }
}

# ElastiCache Redis
resource "aws_elasticache_subnet_group" "main" {
  name       = "restaurant-app-cache-subnet"
  subnet_ids = aws_subnet.private[*].id
}

resource "aws_elasticache_cluster" "main" {
  cluster_id           = "restaurant-app-cache"
  engine               = "redis"
  node_type            = "cache.t3.micro"
  num_cache_nodes      = 1
  parameter_group_name = "default.redis7"
  port                 = 6379
  subnet_group_name    = aws_elasticache_subnet_group.main.name
  security_group_ids   = [aws_security_group.redis.id]
}

ÏûêÎèô ÏÉùÏÑ±Îêú Kubernetes Îß§ÎãàÌéòÏä§Ìä∏:
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: restaurant-app
  labels:
    name: restaurant-app

---
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: restaurant-app
data:
  NODE_ENV: "production"
  REDIS_HOST: "restaurant-app-cache.xxxxx.cache.amazonaws.com"
  REDIS_PORT: "6379"
  LOG_LEVEL: "info"

---
# k8s/secret.yaml  
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: restaurant-app
type: Opaque
data:
  DATABASE_URL: <base64-encoded-value>
  JWT_SECRET: <base64-encoded-value>
  AWS_ACCESS_KEY_ID: <base64-encoded-value>
  AWS_SECRET_ACCESS_KEY: <base64-encoded-value>

---
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: restaurant-app-backend
  namespace: restaurant-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: restaurant-app-backend
  template:
    metadata:
      labels:
        app: restaurant-app-backend
    spec:
      containers:
      - name: backend
        image: your-registry/restaurant-app-backend:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: NODE_ENV
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: DATABASE_URL
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: JWT_SECRET
        resources:
          limits:
            cpu: 500m
            memory: 512Mi
          requests:
            cpu: 250m
            memory: 256Mi
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5

=== Phase 2: Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î∞∞Ìè¨ (30-60Î∂Ñ) ===

ÏûêÎèô ÏÉùÏÑ±Îêú CI/CD ÌååÏù¥ÌîÑÎùºÏù∏:
# .github/workflows/deploy-production.yml
name: Deploy to Production

on:
  push:
    branches: [main]
    tags: ['v*']

env:
  AWS_REGION: us-west-2
  EKS_CLUSTER_NAME: restaurant-app-cluster
  ECR_REPOSITORY: restaurant-app

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run tests
        run: npm run test:ci
      
      - name: Run E2E tests
        run: npm run test:e2e
        
      - name: Security scan
        run: npm audit --audit-level=moderate

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Build and push backend image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG ./backend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY-backend:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-backend:latest
      
      - name: Build and push frontend image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG ./frontend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY-frontend:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY-frontend:latest
      
      - name: Deploy to EKS
        env:
          IMAGE_TAG: ${{ github.sha }}
        run: |
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
          
          # Update image tags in deployment
          sed -i "s|image: your-registry/restaurant-app-backend:latest|image: $ECR_REGISTRY/$ECR_REPOSITORY-backend:$IMAGE_TAG|g" k8s/deployment.yaml
          sed -i "s|image: your-registry/restaurant-app-frontend:latest|image: $ECR_REGISTRY/$ECR_REPOSITORY-frontend:$IMAGE_TAG|g" k8s/deployment.yaml
          
          # Apply Kubernetes manifests
          kubectl apply -f k8s/
          
          # Wait for rollout to complete
          kubectl rollout status deployment/restaurant-app-backend -n restaurant-app --timeout=600s
          kubectl rollout status deployment/restaurant-app-frontend -n restaurant-app --timeout=600s
      
      - name: Run smoke tests
        run: |
          # Get service endpoint
          export APP_URL=$(kubectl get ingress restaurant-app-ingress -n restaurant-app -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          # Wait for service to be ready
          sleep 60
          
          # Run smoke tests
          curl -f http://$APP_URL/health || exit 1
          curl -f http://$APP_URL/api/restaurants/nearby?lat=37.5665&lng=126.9780 || exit 1

Blue-Green Î∞∞Ìè¨ Ïä§ÌÅ¨Î¶ΩÌä∏:
#!/bin/bash
# scripts/blue-green-deploy.sh

set -e

NAMESPACE="restaurant-app"
APP_NAME="restaurant-app-backend"
NEW_VERSION=$1

if [ -z "$NEW_VERSION" ]; then
    echo "Usage: $0 <new-version>"
    exit 1
fi

echo "Starting Blue-Green deployment for version $NEW_VERSION"

# 1. ÌòÑÏû¨ ÌôúÏÑ± Î∞∞Ìè¨ ÌôïÏù∏
CURRENT_COLOR=$(kubectl get service $APP_NAME -n $NAMESPACE -o jsonpath='{.spec.selector.color}')
if [ "$CURRENT_COLOR" = "blue" ]; then
    NEW_COLOR="green"
else
    NEW_COLOR="blue"
fi

echo "Current color: $CURRENT_COLOR, New color: $NEW_COLOR"

# 2. ÏÉà Î≤ÑÏ†Ñ Î∞∞Ìè¨
kubectl set image deployment/$APP_NAME-$NEW_COLOR -n $NAMESPACE \
    backend=your-registry/$APP_NAME:$NEW_VERSION

# 3. Î∞∞Ìè¨ ÏôÑÎ£å ÎåÄÍ∏∞
kubectl rollout status deployment/$APP_NAME-$NEW_COLOR -n $NAMESPACE --timeout=600s

# 4. Health check
ENDPOINT=$(kubectl get ingress $APP_NAME-ingress -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
for i in {1..30}; do
    if curl -f "http://$ENDPOINT/health" > /dev/null 2>&1; then
        echo "Health check passed"
        break
    fi
    echo "Waiting for health check... ($i/30)"
    sleep 10
done

# 5. Ìä∏ÎûòÌîΩ Ï†ÑÌôò
kubectl patch service $APP_NAME -n $NAMESPACE -p '{"spec":{"selector":{"color":"'$NEW_COLOR'"}}}'

echo "Traffic switched to $NEW_COLOR"

# 6. Ïù¥Ï†Ñ Î≤ÑÏ†Ñ Ï†ïÎ¶¨ (5Î∂Ñ ÌõÑ)
echo "Waiting 5 minutes before cleaning up old version..."
sleep 300

kubectl scale deployment $APP_NAME-$CURRENT_COLOR -n $NAMESPACE --replicas=0

echo "Blue-Green deployment completed successfully"

=== Phase 3: Î™®ÎãàÌÑ∞ÎßÅ & Î∂ÑÏÑù ÏÑ§Ï†ï (60-90Î∂Ñ) ===

Prometheus + Grafana Î™®ÎãàÌÑ∞ÎßÅ Ïä§ÌÉù:
# monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093
    
    scrape_configs:
      - job_name: 'restaurant-app-backend'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - restaurant-app
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: restaurant-app-backend
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
      
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)

---
# monitoring/grafana-dashboard.json
{
  "dashboard": {
    "title": "Restaurant App Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{job=\"restaurant-app-backend\"}[5m])) by (method, status_code)",
            "legendFormat": "{{method}} {{status_code}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job=\"restaurant-app-backend\"}[5m])) by (le))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket{job=\"restaurant-app-backend\"}[5m])) by (le))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{job=\"restaurant-app-backend\",status_code=~\"5..\"}[5m])) / sum(rate(http_requests_total{job=\"restaurant-app-backend\"}[5m])) * 100",
            "legendFormat": "Error Rate %"
          }
        ]
      },
      {
        "title": "Active Users",
        "type": "stat",
        "targets": [
          {
            "expr": "active_users_total{job=\"restaurant-app-backend\"}",
            "legendFormat": "Active Users"
          }
        ]
      }
    ]
  }
}

ÏïåÎ¶º Í∑úÏπô ÏÑ§Ï†ï:
# monitoring/alert-rules.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  restaurant-app.yml: |
    groups:
    - name: restaurant-app.rules
      rules:
      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{job="restaurant-app-backend",status_code=~"5.."}[5m])) / sum(rate(http_requests_total{job="restaurant-app-backend"}[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"
      
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="restaurant-app-backend"}[5m])) by (le)) > 2.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"
      
      - alert: LowDiskSpace
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space"
          description: "Disk space is below 20% on {{ $labels.instance }}"
      
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 15 > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Pod is crash looping"
          description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crash looping"

=== Phase 4: ÏµúÏ¢Ö Í≤ÄÏ¶ù & Go-Live (90-120Î∂Ñ) ===

ÏûêÎèô E2E Í≤ÄÏ¶ù Ïä§ÌÅ¨Î¶ΩÌä∏:
#!/bin/bash
# scripts/production-verification.sh

set -e

APP_URL=${1:-"https://restaurant-app.com"}
echo "Starting production verification for $APP_URL"

# 1. Health Check
echo "1. Health Check"
curl -f "$APP_URL/health" || {
    echo "‚ùå Health check failed"
    exit 1
}
echo "‚úÖ Health check passed"

# 2. API Endpoints Test
echo "2. API Endpoints Test"
API_ENDPOINTS=(
    "/api/restaurants/nearby?lat=37.5665&lng=126.9780"
    "/api/categories"
    "/api/auth/check"
)

for endpoint in "${API_ENDPOINTS[@]}"; do
    echo "Testing $endpoint"
    response=$(curl -s -o /dev/null -w "%{http_code}" "$APP_URL$endpoint")
    if [[ "$response" =~ ^(200|401)$ ]]; then
        echo "‚úÖ $endpoint - HTTP $response"
    else
        echo "‚ùå $endpoint - HTTP $response"
        exit 1
    fi
done

# 3. Database Connection Test
echo "3. Database Connection Test"
response=$(curl -s "$APP_URL/health/db")
if echo "$response" | grep -q "ok"; then
    echo "‚úÖ Database connection healthy"
else
    echo "‚ùå Database connection failed"
    exit 1
fi

# 4. Cache Test
echo "4. Cache Test"
response=$(curl -s "$APP_URL/health/cache")
if echo "$response" | grep -q "ok"; then
    echo "‚úÖ Cache connection healthy"
else
    echo "‚ùå Cache connection failed"
    exit 1
fi

# 5. Load Test
echo "5. Load Test"
ab -n 1000 -c 10 "$APP_URL/" > /tmp/load_test.txt
avg_time=$(grep "Time per request" /tmp/load_test.txt | head -1 | awk '{print $4}')
if (( $(echo "$avg_time < 500" | bc -l) )); then
    echo "‚úÖ Load test passed - Average response time: ${avg_time}ms"
else
    echo "‚ùå Load test failed - Average response time: ${avg_time}ms"
    exit 1
fi

echo "üéâ All production verification tests passed!"

DNS Ï†ÑÌôò Ïä§ÌÅ¨Î¶ΩÌä∏:
#!/bin/bash
# scripts/dns-cutover.sh

DOMAIN="restaurant-app.com"
NEW_IP=$1

if [ -z "$NEW_IP" ]; then
    echo "Usage: $0 <new-ip-address>"
    exit 1
fi

echo "Starting DNS cutover for $DOMAIN to $NEW_IP"

# 1. CloudFlare DNS ÏóÖÎç∞Ïù¥Ìä∏
curl -X PUT "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/dns_records/$CLOUDFLARE_RECORD_ID" \
    -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
    -H "Content-Type: application/json" \
    --data '{
        "type": "A",
        "name": "'$DOMAIN'",
        "content": "'$NEW_IP'",
        "ttl": 300
    }'

# 2. DNS Ï†ÑÌåå ÌôïÏù∏
echo "Waiting for DNS propagation..."
for i in {1..30}; do
    resolved_ip=$(dig +short $DOMAIN @8.8.8.8)
    if [ "$resolved_ip" = "$NEW_IP" ]; then
        echo "‚úÖ DNS propagation completed"
        break
    fi
    echo "Waiting for DNS propagation... ($i/30)"
    sleep 10
done

# 3. CDN Ï∫êÏãú ÌçºÏßÄ
curl -X POST "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/purge_cache" \
    -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
    -H "Content-Type: application/json" \
    --data '{"purge_everything":true}'

echo "üéâ DNS cutover completed successfully!"
```

### **ÏãúÎÇòÎ¶¨Ïò§ 2: B2B SaaS ÏûêÎèô Îü∞Ïπ≠**

```yaml
ÏûÖÎ†•: SaaS MVP (Ïû¨Í≥† Í¥ÄÎ¶¨ ÏãúÏä§ÌÖú)

ÌäπÌôî Îü∞Ïπ≠ ÏöîÍµ¨ÏÇ¨Ìï≠:
  - Î©ÄÌã∞ÌÖåÎÑåÌä∏ ÏïÑÌÇ§ÌÖçÏ≤ò
  - Îç∞Ïù¥ÌÑ∞ Í≤©Î¶¨ Î∞è Î≥¥Ïïà
  - ÏÇ¨Ïö©Îüâ Í∏∞Î∞ò Í≥ºÍ∏à Ïó∞Îèô
  - ÏóîÌÑ∞ÌîÑÎùºÏù¥Ï¶à SLA Î≥¥Ïû•

ÏûêÎèô Íµ¨ÏÑ±:
  ‚úÖ Kubernetes Namespace per Tenant
  ‚úÖ Database Schema Isolation  
  ‚úÖ API Rate Limiting
  ‚úÖ Usage Tracking & Billing
  ‚úÖ 99.9% SLA Î™®ÎãàÌÑ∞ÎßÅ
  ‚úÖ GDPR/SOC2 Ï§ÄÏàò ÏÑ§Ï†ï
  ‚úÖ Backup & Disaster Recovery
  ‚úÖ Auto-scaling Ï†ïÏ±Ö
```

---

## üéõÔ∏è AI Îü∞Ïπ≠ ÏûêÎèôÌôî ÏóîÏßÑ

### **Ïù∏ÌîÑÎùº ÏûêÎèô ÌîÑÎ°úÎπÑÏ†ÄÎãù**
```python
class InfrastructureProvisioner:
    def __init__(self):
        self.terraform_generator = TerraformGenerator()
        self.k8s_generator = KubernetesGenerator()
        self.monitoring_setup = MonitoringSetup()
    
    def provision_infrastructure(self, app_requirements):
        # 1. ÌÅ¥ÎùºÏö∞Îìú Î¶¨ÏÜåÏä§ Í≥ÑÏÇ∞
        resource_specs = self.calculate_resource_requirements(app_requirements)
        
        # 2. Terraform ÏΩîÎìú ÏÉùÏÑ±
        terraform_code = self.terraform_generator.generate(
            resource_specs,
            app_requirements.cloud_provider,
            app_requirements.region
        )
        
        # 3. Kubernetes Îß§ÎãàÌéòÏä§Ìä∏ ÏÉùÏÑ±
        k8s_manifests = self.k8s_generator.generate(
            app_requirements.containers,
            resource_specs
        )
        
        # 4. Î™®ÎãàÌÑ∞ÎßÅ Ïä§ÌÉù ÏÑ§Ï†ï
        monitoring_config = self.monitoring_setup.generate(
            app_requirements.monitoring_requirements
        )
        
        return {
            'terraform': terraform_code,
            'kubernetes': k8s_manifests,
            'monitoring': monitoring_config,
            'estimated_cost': resource_specs.monthly_cost
        }
```

### **Î∞∞Ìè¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÉùÏÑ±Í∏∞**
```javascript
class DeploymentPipelineGenerator {
  generateCIPipeline(appSpecs, deploymentStrategy) {
    const pipeline = {
      name: `${appSpecs.name}-production-deploy`,
      triggers: this.generateTriggers(appSpecs.git_settings),
      stages: []
    };
    
    // Test Stage
    pipeline.stages.push({
      name: 'test',
      jobs: [
        this.generateUnitTestJob(appSpecs),
        this.generateIntegrationTestJob(appSpecs),
        this.generateSecurityScanJob(appSpecs)
      ]
    });
    
    // Build Stage
    pipeline.stages.push({
      name: 'build',
      jobs: [
        this.generateDockerBuildJob(appSpecs),
        this.generateImageScanJob(appSpecs)
      ]
    });
    
    // Deploy Stage
    pipeline.stages.push({
      name: 'deploy',
      deployment_strategy: deploymentStrategy,
      jobs: [
        this.generateDeploymentJob(appSpecs, deploymentStrategy),
        this.generateSmokeTestJob(appSpecs),
        this.generateNotificationJob(appSpecs)
      ]
    });
    
    return pipeline;
  }
}
```

---

## üîß Íµ¨ÌòÑ Í∞ÄÏù¥Îìú

### **Îü∞Ïπ≠ ÏûêÎèôÌôî Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞**
```javascript
class LaunchAutomator {
  constructor() {
    this.infraProvisioner = new InfrastructureProvisioner();
    this.pipelineGenerator = new DeploymentPipelineGenerator();
    this.monitoringSetup = new MonitoringSetup();
    this.verificationBot = new ProductionVerificationBot();
  }
  
  async autoLaunch(mvp, launchConfig) {
    console.log('üöÄ Starting automated launch process...');
    
    // Phase 1: Infrastructure (0-30Î∂Ñ)
    console.log('Phase 1: Provisioning infrastructure...');
    const infrastructure = await this.infraProvisioner.provision(mvp, launchConfig);
    
    // Phase 2: Deployment (30-60Î∂Ñ)
    console.log('Phase 2: Deploying application...');
    const deployment = await this.deployApplication(mvp, infrastructure);
    
    // Phase 3: Monitoring (60-90Î∂Ñ)
    console.log('Phase 3: Setting up monitoring...');
    const monitoring = await this.monitoringSetup.configure(mvp, infrastructure);
    
    // Phase 4: Verification (90-120Î∂Ñ)
    console.log('Phase 4: Running production verification...');
    const verification = await this.verificationBot.verify(deployment);
    
    // Go-Live
    if (verification.all_passed) {
      console.log('üéâ Go-Live: Activating production traffic...');
      await this.activateProduction(deployment);
      
      return {
        status: 'success',
        launch_time: '2 hours',
        infrastructure: infrastructure,
        monitoring_dashboard: monitoring.dashboard_url,
        application_url: deployment.production_url
      };
    } else {
      throw new Error('Production verification failed: ' + verification.failures.join(', '));
    }
  }
}
```

### **Î™®ÎãàÌÑ∞ÎßÅ ÏûêÎèô ÏÑ§Ï†ï**
```python
class MonitoringAutoSetup:
    def __init__(self):
        self.prometheus_config = PrometheusConfig()
        self.grafana_dashboards = GrafanaDashboards()
        self.alert_rules = AlertRules()
    
    def setup_monitoring_stack(self, app_specs):
        monitoring_config = {}
        
        # 1. Prometheus ÏÑ§Ï†ï ÏÉùÏÑ±
        monitoring_config['prometheus'] = self.prometheus_config.generate(
            app_specs.service_endpoints,
            app_specs.custom_metrics
        )
        
        # 2. Grafana ÎåÄÏãúÎ≥¥Îìú ÏÉùÏÑ±
        monitoring_config['grafana'] = self.grafana_dashboards.create(
            app_specs.app_type,
            app_specs.business_metrics
        )
        
        # 3. ÏïåÎ¶º Í∑úÏπô ÏÑ§Ï†ï
        monitoring_config['alerts'] = self.alert_rules.generate(
            app_specs.sla_requirements,
            app_specs.notification_channels
        )
        
        # 4. Î°úÍ∑∏ ÏàòÏßë ÏÑ§Ï†ï
        monitoring_config['logging'] = self.setup_logging_stack(app_specs)
        
        return monitoring_config
```

---

## üìä ÌíàÏßà Î≥¥Ï¶ù

### **ÌîÑÎ°úÎçïÏÖò Ï§ÄÎπÑÎèÑ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏**
```yaml
Ïù∏ÌîÑÎùº Ï§ÄÎπÑÎèÑ: (100%)
  ‚úÖ High Availability ÏÑ§Ï†ï
  ‚úÖ Auto Scaling Ï†ïÏ±Ö
  ‚úÖ Load Balancer Íµ¨ÏÑ±
  ‚úÖ SSL/TLS Ïù∏Ï¶ùÏÑú
  ‚úÖ Backup Î∞è Î≥µÍµ¨ Ï†àÏ∞®
  ‚úÖ Î≥¥Ïïà Í∑∏Î£π ÏÑ§Ï†ï
  ‚úÖ DNS ÏÑ§Ï†ï ÏôÑÎ£å

Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Ï§ÄÎπÑÎèÑ: (95%+)
  ‚úÖ Health Check ÏóîÎìúÌè¨Ïù∏Ìä∏
  ‚úÖ Graceful Shutdown
  ‚úÖ Configuration Ïô∏Î∂ÄÌôî
  ‚úÖ Î°úÍ∑∏ Íµ¨Ï°∞Ìôî
  ‚úÖ Î©îÌä∏Î¶≠ ÏàòÏßë
  ‚úÖ Error Handling
  ‚úÖ Rate Limiting

Î™®ÎãàÌÑ∞ÎßÅ Ï§ÄÎπÑÎèÑ: (90%+)
  ‚úÖ Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î©îÌä∏Î¶≠
  ‚úÖ Ïù∏ÌîÑÎùº Î©îÌä∏Î¶≠
  ‚úÖ Î°úÍ∑∏ ÏàòÏßë
  ‚úÖ ÏïåÎ¶º Í∑úÏπô
  ‚úÖ ÎåÄÏãúÎ≥¥Îìú Íµ¨ÏÑ±
  ‚úÖ SLA Î™®ÎãàÌÑ∞ÎßÅ
```

### **ÏûêÎèô Í≤ÄÏ¶ù ÏãúÏä§ÌÖú**
```python
class ProductionVerificationBot:
    def __init__(self):
        self.health_checker = HealthChecker()
        self.load_tester = LoadTester()
        self.security_scanner = SecurityScanner()
        self.sla_validator = SLAValidator()
    
    async def verify_production_readiness(self, deployment):
        verification_results = {}
        
        # 1. Health Check Í≤ÄÏ¶ù
        verification_results['health'] = await self.health_checker.verify(
            deployment.health_endpoints
        )
        
        # 2. ÏÑ±Îä• Í≤ÄÏ¶ù
        verification_results['performance'] = await self.load_tester.test(
            deployment.app_url,
            expected_rps=100,
            max_response_time=500
        )
        
        # 3. Î≥¥Ïïà Í≤ÄÏ¶ù
        verification_results['security'] = await self.security_scanner.scan(
            deployment.app_url
        )
        
        # 4. SLA Ï§ÄÏàò Í≤ÄÏ¶ù
        verification_results['sla'] = await self.sla_validator.validate(
            deployment.monitoring_config
        )
        
        # Ï¢ÖÌï© ÌèâÍ∞Ä
        overall_score = self.calculate_readiness_score(verification_results)
        
        return {
            'ready_for_production': overall_score >= 0.95,
            'overall_score': overall_score,
            'results': verification_results,
            'recommendations': self.generate_recommendations(verification_results)
        }
```

---

## üéØ Í≥†Í∏â Í∏∞Îä•

### **ÏßÄÎä•Ìòï Ïä§ÏºÄÏùºÎßÅ**
```yaml
Auto Scaling Ï†ïÏ±Ö:
  CPU Í∏∞Î∞ò:
    - Target: 70% CPU ÏÇ¨Ïö©Î•†
    - Scale Up: 2Î∂Ñ Ïó∞ÏÜç Ï¥àÍ≥º Ïãú
    - Scale Down: 5Î∂Ñ Ïó∞ÏÜç ÎØ∏Îßå Ïãú
  
  Î©îÎ™®Î¶¨ Í∏∞Î∞ò:
    - Target: 80% Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Î•†
    - Predictive Scaling Ï†ÅÏö©
  
  Ïª§Ïä§ÌÖÄ Î©îÌä∏Î¶≠:
    - Queue Length > 100
    - Response Time > 500ms
    - Error Rate > 1%
```

### **Ïû¨Ìï¥ Î≥µÍµ¨ ÏûêÎèôÌôî**
```yaml
Disaster Recovery:
  RTO (Recovery Time Objective): 15Î∂Ñ
  RPO (Recovery Point Objective): 5Î∂Ñ
  
  ÏûêÎèô Î∞±ÏóÖ:
    - Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§: Îß§ 6ÏãúÍ∞Ñ
    - ÌååÏùº ÏãúÏä§ÌÖú: Îß§ 24ÏãúÍ∞Ñ
    - ÏÑ§Ï†ï ÌååÏùº: Îß§ Î∞∞Ìè¨ Ïãú
  
  ÏûêÎèô Î≥µÍµ¨:
    - Health Check Ïã§Ìå® Ïãú ÏûêÎèô Ïû¨ÏãúÏûë
    - Îã§Ï§ë AZ ÌéòÏùºÏò§Î≤Ñ
    - DNS ÏûêÎèô Ï†ÑÌôò
```

### **Î≥¥Ïïà ÏûêÎèôÌôî**
```yaml
Security Automation:
  Ï∑®ÏïΩÏ†ê Ïä§Ï∫î:
    - Ïª®ÌÖåÏù¥ÎÑà Ïù¥ÎØ∏ÏßÄ Ïä§Ï∫î
    - ÏùòÏ°¥ÏÑ± Ï∑®ÏïΩÏ†ê Ï≤¥ÌÅ¨
    - OWASP Top 10 Í≤ÄÏ¶ù
  
  Î≥¥Ïïà Î™®ÎãàÌÑ∞ÎßÅ:
    - ÎπÑÏ†ïÏÉÅ Ìä∏ÎûòÌîΩ ÌÉêÏßÄ
    - Ïπ®ÏûÖ ÌÉêÏßÄ ÏãúÏä§ÌÖú
    - Î≥¥Ïïà Î°úÍ∑∏ Î∂ÑÏÑù
  
  Í∑úÏ†ï Ï§ÄÏàò:
    - GDPR Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
    - SOC2 Ïª®Ìä∏Î°§ Íµ¨ÌòÑ
    - PCI DSS Ï§ÄÏàò (Í≤∞Ï†ú Ïãú)
```

---

## üìà ÏÑ±Í≥º Ï∏°Ï†ï

### **Îü∞Ïπ≠ Ìö®Ïú®ÏÑ±**
- **Í∏∞Ï°¥ Î∞©Ïãù**: 2-3Ïùº (ÏàòÎèô Î∞∞Ìè¨ + Í≤ÄÏ¶ù)
- **AI Î∞©Ïãù**: 2ÏãúÍ∞Ñ (ÏôÑÏ†Ñ ÏûêÎèôÌôî)
- **ÏãúÍ∞Ñ Îã®Ï∂ï**: 92% (48ÏãúÍ∞Ñ ‚Üí 2ÏãúÍ∞Ñ)

### **Ïö¥ÏòÅ ÏïàÏ†ïÏÑ±**
- **Í∞ÄÏö©ÏÑ±**: 99.9% SLA Îã¨ÏÑ±
- **MTTR**: 5Î∂Ñ Ïù¥ÎÇ¥ ÏûêÎèô Î≥µÍµ¨
- **Î∞∞Ìè¨ ÏÑ±Í≥µÎ•†**: 98.5%
- **Î≥¥Ïïà ÏÇ¨Í≥†**: 0Í±¥ (ÏûêÎèô Î≥¥Ïïà Ï†ÅÏö©)

### **ÎπÑÏö© ÏµúÏ†ÅÌôî**
- **Ïù∏ÌîÑÎùº ÎπÑÏö©**: 30% Ï†àÍ∞ê (Î¶¨ÏÜåÏä§ ÏµúÏ†ÅÌôî)
- **Ïö¥ÏòÅ Ïù∏Î†•**: 80% Ï†àÍ∞ê (ÏûêÎèôÌôî)
- **Î∞∞Ìè¨ ÎπÑÏö©**: 95% Ï†àÍ∞ê (ÏûêÎèô Î∞∞Ìè¨)

---

## üîó Îã§Ïùå Îã®Í≥Ñ

1. **AI Interview System** - ÏÇ¨Ïö©Ïûê ÌîºÎìúÎ∞± ÏûêÎèô ÏàòÏßë
2. **Industry Templates** - ÏóÖÍ≥ÑÎ≥Ñ Îü∞Ïπ≠ ÏµúÏ†ÅÌôî
3. **Visual Builder** - ÎÖ∏ÏΩîÎìú Ïö¥ÏòÅ ÎèÑÍµ¨

---

**üí° ÌïµÏã¨ Î©îÏãúÏßÄ**: 2ÏãúÍ∞Ñ Launch AutomationÏùÄ Îã®ÏàúÌïú Î∞∞Ìè¨ ÏûêÎèôÌôîÎ•º ÎÑòÏñ¥ÏÑú, AIÏùò ÏßÄÎä•Ï†Å Ïö¥ÏòÅ ÏûêÎèôÌôîÎ•º ÌÜµÌï¥ ÏïàÏ†ïÏ†ÅÏù¥Í≥† ÌôïÏû• Í∞ÄÎä•Ìïú ÌîÑÎ°úÎçïÏÖò ÏÑúÎπÑÏä§Î•º Ï¶âÏãú Ï†úÍ≥µÌï©ÎãàÎã§.